{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scCe1ygqEojZ"
      },
      "source": [
        "# Final Project: \n",
        "Dartmouth College, LING48, Spring 2023<br>\n",
        "Jackline Gathoni Wambui (jackline.w.gathoni.24@dartmouth.edu)                             \n",
        "Dahlia Igiraneza (dahlia.igiraneza.24@dartmouth.edu)                                                \n",
        "Paige Nakai (paige.m.nakai.24@dartmouth.edu)\n",
        "\n",
        "\n",
        "To complete this project, we consulted the following sources:\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f                                       \n",
        "https://stackabuse.com/text-classification-with-bert-tokenizer-and-tf-2-0-in-python/                    \n",
        "https://nlp.stanford.edu/software/CRF-NER.html#Download                      \n",
        "\n",
        "https://lvngd.com/blog/text-classification-with-python-and-scikit-learn/#classification-model-metrics\n",
        "https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icdXzw65FeBu"
      },
      "source": [
        "Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4o14RbTE90A",
        "outputId": "91a21694-5708-47a7-bdba-b13560920ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import regex as re\n",
        "import torch\n",
        "import numpy as np\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5bcMWlncEm-"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AAkCJ4Ck6-ir",
        "outputId": "643e453d-2cde-437b-ef9d-d1357a073cdb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-01468b8a-ab62-4bac-8f9f-be54f30f14d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Emails</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>Related</td>\n",
              "      <td>Can anyone take my Saturday shift 4-8pm at circ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Related</td>\n",
              "      <td>Hello All,\\r\\n\\r\\nSorry for the short notice, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>Related</td>\n",
              "      <td>does anyone want orozco 7-8 tonight?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Related</td>\n",
              "      <td>Hello All,\\r\\n\\r\\nI have a midterm at 7:00 pm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Related</td>\n",
              "      <td>Hello all!\\r\\n\\r\\nReaching out to see if anyon...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01468b8a-ab62-4bac-8f9f-be54f30f14d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01468b8a-ab62-4bac-8f9f-be54f30f14d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01468b8a-ab62-4bac-8f9f-be54f30f14d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Category                                             Emails\n",
              "234  Related    Can anyone take my Saturday shift 4-8pm at circ\n",
              "31   Related  Hello All,\\r\\n\\r\\nSorry for the short notice, ...\n",
              "225  Related               does anyone want orozco 7-8 tonight?\n",
              "4    Related  Hello All,\\r\\n\\r\\nI have a midterm at 7:00 pm ...\n",
              "56   Related  Hello all!\\r\\n\\r\\nReaching out to see if anyon..."
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datapath = \"/content/CS72 Project_Emails_training_dataset - Sheet1.csv\"\n",
        "df= pd.read_csv(datapath, encoding=\"'latin1\")\n",
        "df = df.dropna()\n",
        "df.isnull().values.any()\n",
        "df = df.sample(frac=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "DKf_5nL06-mN",
        "outputId": "8d0ac5ea-13cd-446d-fe06-f6bda774d950"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='Category'>"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAHnCAYAAACSW6Z5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmtElEQVR4nO3dfVRVBbrH8d8BgZQExATEMDXFt6y8elPUnAoKX8au5vVmOU05aHcctJLshXtLq+Vkow2aDclMM4m2erXMljVZhompiIVl5qgpY6IhajKA4BUQ9v2j1VlzRiuRl/2A389aey3P3vtsnuMapq/77LOPx3EcRwAAAIb4uT0AAADAvyJQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYE4rtwc4H7W1tSosLFTbtm3l8XjcHgcAAJwDx3F04sQJRUdHy8/vx8+RNMtAKSwsVExMjNtjAACA83Dw4EFdeumlP7pPswyUtm3bSvruBYaEhLg8DQAAOBdlZWWKiYnx/nf8xzTLQPn+bZ2QkBACBQCAZuZcLs/gIlkAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAnFZuD4C66fLwu26PgCb09VOj3R4BAFzBGRQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYU6dAmTdvnv793/9dbdu2VUREhMaOHas9e/b47HPq1CklJyerffv2uvjiizV+/HgdOXLEZ5+CggKNHj1abdq0UUREhB544AGdPn26/q8GAAC0CHUKlOzsbCUnJ2vLli1au3atqqurddNNN6miosK7z8yZM7V69WqtWLFC2dnZKiws1C233OLdXlNTo9GjR6uqqkqbN2/WsmXLlJmZqdmzZzfcqwIAAM2ax3Ec53yffOzYMUVERCg7O1vDhw9XaWmpOnTooJdffln/+Z//KUnavXu3evfurZycHA0ePFjvvfeefv7zn6uwsFCRkZGSpIyMDD300EM6duyYAgMDf/LnlpWVKTQ0VKWlpQoJCTnf8ZulLg+/6/YIaEJfPzXa7REAoMHU5b/f9boGpbS0VJIUHh4uScrLy1N1dbUSEhK8+/Tq1UudO3dWTk6OJCknJ0f9+vXzxokkJSYmqqysTDt37jzrz6msrFRZWZnPAgAAWq7zDpTa2lrdd999Gjp0qK644gpJUlFRkQIDAxUWFuazb2RkpIqKirz7/HOcfL/9+21nM2/ePIWGhnqXmJiY8x0bAAA0A+cdKMnJyfryyy/16quvNuQ8Z5WamqrS0lLvcvDgwUb/mQAAwD2tzudJ06dP1zvvvKMNGzbo0ksv9a6PiopSVVWVSkpKfM6iHDlyRFFRUd59tm7d6nO87z/l8/0+/yooKEhBQUHnMyoAAGiG6nQGxXEcTZ8+XW+99ZbWrVunrl27+mwfMGCAAgIClJWV5V23Z88eFRQUKC4uTpIUFxenHTt26OjRo9591q5dq5CQEPXp06c+rwUAALQQdTqDkpycrJdffllvv/222rZt671mJDQ0VK1bt1ZoaKiSkpKUkpKi8PBwhYSEaMaMGYqLi9PgwYMlSTfddJP69OmjO+64Q/Pnz1dRUZEeeeQRJScnc5YEAABIqmOgLFmyRJJ03XXX+axfunSp7rrrLknSwoUL5efnp/Hjx6uyslKJiYl67rnnvPv6+/vrnXfe0bRp0xQXF6fg4GDdeeedeuKJJ+r3SgAAQItRr/uguIX7oOBCwX1QALQkTXYfFAAAgMZAoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwp86BsmHDBo0ZM0bR0dHyeDxatWqVz/a77rpLHo/HZxkxYoTPPsXFxZo0aZJCQkIUFhampKQklZeX1+uFAACAlqPOgVJRUaGrrrpK6enpP7jPiBEjdPjwYe/yyiuv+GyfNGmSdu7cqbVr1+qdd97Rhg0bdPfdd9d9egAA0CK1qusTRo4cqZEjR/7oPkFBQYqKijrrtl27dmnNmjX65JNPNHDgQEnSs88+q1GjRunpp59WdHR0XUcCAAAtTKNcg7J+/XpFRESoZ8+emjZtmo4fP+7dlpOTo7CwMG+cSFJCQoL8/PyUm5t71uNVVlaqrKzMZwEAAC1XgwfKiBEjtHz5cmVlZel3v/udsrOzNXLkSNXU1EiSioqKFBER4fOcVq1aKTw8XEVFRWc95rx58xQaGupdYmJiGnpsAABgSJ3f4vkpEydO9P65X79+uvLKK3X55Zdr/fr1io+PP69jpqamKiUlxfu4rKyMSAEAoAVr9I8Zd+vWTZdccon27dsnSYqKitLRo0d99jl9+rSKi4t/8LqVoKAghYSE+CwAAKDlavRAOXTokI4fP66OHTtKkuLi4lRSUqK8vDzvPuvWrVNtba0GDRrU2OMAAIBmoM5v8ZSXl3vPhkjS/v379fnnnys8PFzh4eF6/PHHNX78eEVFRSk/P18PPvigunfvrsTERElS7969NWLECE2dOlUZGRmqrq7W9OnTNXHiRD7BAwAAJJ3HGZRPP/1U/fv3V//+/SVJKSkp6t+/v2bPni1/f3998cUXuvnmmxUbG6ukpCQNGDBAH3/8sYKCgrzHeOmll9SrVy/Fx8dr1KhRGjZsmP70pz813KsCAADNWp3PoFx33XVyHOcHt7///vs/eYzw8HC9/PLLdf3RAADgAsF38QAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADm1DlQNmzYoDFjxig6Oloej0erVq3y2e44jmbPnq2OHTuqdevWSkhI0N69e332KS4u1qRJkxQSEqKwsDAlJSWpvLy8Xi8EAAC0HHUOlIqKCl111VVKT08/6/b58+dr8eLFysjIUG5uroKDg5WYmKhTp05595k0aZJ27typtWvX6p133tGGDRt09913n/+rAAAALUqruj5h5MiRGjly5Fm3OY6jRYsW6ZFHHtF//Md/SJKWL1+uyMhIrVq1ShMnTtSuXbu0Zs0affLJJxo4cKAk6dlnn9WoUaP09NNPKzo6uh4vBwAAtAQNeg3K/v37VVRUpISEBO+60NBQDRo0SDk5OZKknJwchYWFeeNEkhISEuTn56fc3NyzHreyslJlZWU+CwAAaLkaNFCKiookSZGRkT7rIyMjvduKiooUERHhs71Vq1YKDw/37vOv5s2bp9DQUO8SExPTkGMDAABjmsWneFJTU1VaWupdDh486PZIAACgETVooERFRUmSjhw54rP+yJEj3m1RUVE6evSoz/bTp0+ruLjYu8+/CgoKUkhIiM8CAABargYNlK5duyoqKkpZWVnedWVlZcrNzVVcXJwkKS4uTiUlJcrLy/Pus27dOtXW1mrQoEENOQ4AAGim6vwpnvLycu3bt8/7eP/+/fr8888VHh6uzp0767777tPcuXPVo0cPde3aVY8++qiio6M1duxYSVLv3r01YsQITZ06VRkZGaqurtb06dM1ceJEPsEDAAAknUegfPrpp7r++uu9j1NSUiRJd955pzIzM/Xggw+qoqJCd999t0pKSjRs2DCtWbNGF110kfc5L730kqZPn674+Hj5+flp/PjxWrx4cQO8HAAA0BJ4HMdx3B6irsrKyhQaGqrS0tIL7nqULg+/6/YIaEJfPzXa7REAoMHU5b/fzeJTPAAA4MJCoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzGnl9gAAgO90efhdt0dAE/r6qdFuj2AaZ1AAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5DR4ojz32mDwej8/Sq1cv7/ZTp04pOTlZ7du318UXX6zx48fryJEjDT0GAABoxhrlDErfvn11+PBh77Jx40bvtpkzZ2r16tVasWKFsrOzVVhYqFtuuaUxxgAAAM1Uq0Y5aKtWioqKOmN9aWmp/vKXv+jll1/WDTfcIElaunSpevfurS1btmjw4MGNMQ4AAGhmGuUMyt69exUdHa1u3bpp0qRJKigokCTl5eWpurpaCQkJ3n179eqlzp07Kycn5wePV1lZqbKyMp8FAAC0XA0eKIMGDVJmZqbWrFmjJUuWaP/+/br22mt14sQJFRUVKTAwUGFhYT7PiYyMVFFR0Q8ec968eQoNDfUuMTExDT02AAAwpMHf4hk5cqT3z1deeaUGDRqkyy67TK+//rpat259XsdMTU1VSkqK93FZWRmRAgBAC9boHzMOCwtTbGys9u3bp6ioKFVVVamkpMRnnyNHjpz1mpXvBQUFKSQkxGcBAAAtV6MHSnl5ufLz89WxY0cNGDBAAQEBysrK8m7fs2ePCgoKFBcX19ijAACAZqLB3+KZNWuWxowZo8suu0yFhYWaM2eO/P39ddtttyk0NFRJSUlKSUlReHi4QkJCNGPGDMXFxfEJHgAA4NXggXLo0CHddtttOn78uDp06KBhw4Zpy5Yt6tChgyRp4cKF8vPz0/jx41VZWanExEQ999xzDT0GAABoxho8UF599dUf3X7RRRcpPT1d6enpDf2jAQBAC8F38QAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmuBoo6enp6tKliy666CINGjRIW7dudXMcAABghGuB8tprryklJUVz5szRtm3bdNVVVykxMVFHjx51ayQAAGCEa4GSlpamqVOnavLkyerTp48yMjLUpk0bvfDCC26NBAAAjGjlxg+tqqpSXl6eUlNTvev8/PyUkJCgnJycM/avrKxUZWWl93FpaakkqaysrPGHNaa28qTbI6AJXYj/G7+Q8ft9YbkQf7+/f82O4/zkvq4EyrfffquamhpFRkb6rI+MjNTu3bvP2H/evHl6/PHHz1gfExPTaDMCFoQucnsCAI3lQv79PnHihEJDQ390H1cCpa5SU1OVkpLifVxbW6vi4mK1b99eHo/HxcnQFMrKyhQTE6ODBw8qJCTE7XEANCB+vy8sjuPoxIkTio6O/sl9XQmUSy65RP7+/jpy5IjP+iNHjigqKuqM/YOCghQUFOSzLiwsrDFHhEEhISH8HxjQQvH7feH4qTMn33PlItnAwEANGDBAWVlZ3nW1tbXKyspSXFycGyMBAABDXHuLJyUlRXfeeacGDhyoa665RosWLVJFRYUmT57s1kgAAMAI1wLl1ltv1bFjxzR79mwVFRXp6quv1po1a864cBYICgrSnDlzznibD0Dzx+83fojHOZfP+gAAADQhvosHAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5jSLLwvEheGfvxDyp6SlpTXiJAAAtxEoMOOzzz7zebxt2zadPn1aPXv2lCR99dVX8vf314ABA9wYD0A9tGvX7py/fb64uLiRp0FzQKDAjI8++sj757S0NLVt21bLli1Tu3btJEn/+Mc/NHnyZF177bVujQjgPC1atMj75+PHj2vu3LlKTEz0fkFsTk6O3n//fT366KMuTQhruNU9TOrUqZM++OAD9e3b12f9l19+qZtuukmFhYUuTQagvsaPH6/rr79e06dP91n/hz/8QR9++KFWrVrlzmAwhYtkYVJZWZmOHTt2xvpjx47pxIkTLkwEoKG8//77GjFixBnrR4wYoQ8//NCFiWARgQKTxo0bp8mTJ2vlypU6dOiQDh06pDfffFNJSUm65ZZb3B4PQD20b99eb7/99hnr3377bbVv396FiWAR16DApIyMDM2aNUu33367qqurJUmtWrVSUlKSFixY4PJ0AOrj8ccf15QpU7R+/XoNGjRIkpSbm6s1a9bo+eefd3k6WME1KDCtoqJC+fn5kqTLL79cwcHBLk8EoCHk5uZq8eLF2rVrlySpd+/euueee7zBAhAoMG3fvn3Kz8/X8OHD1bp1azmOc84fVQQANF9cgwKTjh8/rvj4eMXGxmrUqFE6fPiwJCkpKUn333+/y9MBqK/8/Hw98sgjuv3223X06FFJ0nvvvaedO3e6PBmsIFBg0syZMxUQEKCCggK1adPGu/7WW2/VmjVrXJwMQH1lZ2erX79+ys3N1Ztvvqny8nJJ0vbt2zVnzhyXp4MVBApM+uCDD/S73/1Ol156qc/6Hj166MCBAy5NBaAhPPzww5o7d67Wrl2rwMBA7/obbrhBW7ZscXEyWEKgwKSKigqfMyffKy4uVlBQkAsTAWgoO3bs0Lhx485YHxERoW+//daFiWARgQKTrr32Wi1fvtz72OPxqLa2VvPnz9f111/v4mQA6issLMx7Xdk/++yzz9SpUycXJoJF3AcFJs2fP1/x8fH69NNPVVVVpQcffFA7d+5UcXGxNm3a5PZ4AOph4sSJeuihh7RixQrvPz42bdqkWbNm6Ze//KXb48EIPmYMs0pLS/WHP/xB27dvV3l5uf7t3/5NycnJ6tixo9ujAaiHqqoqJScnKzMzUzU1NWrVqpVqamp0++23KzMzU/7+/m6PCAMIFJhUUFCgmJiYs97zpKCgQJ07d3ZhKgAN6eDBg9qxY4fKy8vVv39/9ejRw+2RYAiBApP8/f11+PBhRURE+Kw/fvy4IiIiVFNT49JkAOrriSee0KxZs864EP7//u//tGDBAs2ePdulyWAJgQKT/Pz8dOTIEXXo0MFn/YEDB9SnTx9VVFS4NBmA+uIfIDgXXCQLU1JSUiR996mdRx991OdfWDU1NcrNzdXVV1/t0nQAGsIPfWXF9u3bFR4e7sJEsIhAgSmfffaZpO/+D2zHjh0+N3EKDAzUVVddpVmzZrk1HoB6aNeunTwejzwej2JjY30ipaamRuXl5fr1r3/t4oSwhLd4YNLkyZP1zDPPKCQkxO1RADSQZcuWyXEc/epXv9KiRYsUGhrq3RYYGKguXbooLi7OxQlhCYECAGhS2dnZGjJkiAICAtweBYYRKDDr008/1euvv66CggJVVVX5bFu5cqVLUwFoSKdOnTrj95szp5C41T2MevXVVzVkyBDt2rVLb731lqqrq7Vz506tW7fO57QwgObn5MmTmj59uiIiIhQcHKx27dr5LIBEoMCoJ598UgsXLtTq1asVGBioZ555Rrt379Z//dd/cZM2oJl74IEHtG7dOi1ZskRBQUH685//rMcff1zR0dE+38GFCxtv8cCk4OBg7dy5U126dFH79u21fv169evXT7t27dINN9xw1i8aA9A8dO7cWcuXL9d1112nkJAQbdu2Td27d9eLL76oV155RX/961/dHhEGcAYFJrVr104nTpyQJHXq1ElffvmlJKmkpEQnT550czQA9VRcXKxu3bpJ+u56k+LiYknSsGHDtGHDBjdHgyEECkwaPny41q5dK0maMGGC7r33Xk2dOlW33Xab4uPjXZ4OQH1069ZN+/fvlyT16tVLr7/+uiRp9erVCgsLc3EyWMJbPDCpuLhYp06dUnR0tGprazV//nxt3rxZPXr00COPPMKFdEAztnDhQvn7++uee+7Rhx9+qDFjxshxHFVXVystLU333nuv2yPCAAIFAOCqAwcOKC8vT927d9eVV17p9jgwgkCBGWVlZee8L/dJAICWjUCBGX5+fmf9ArF/9v2XjPFtp0Dzsnjx4nPe95577mnESdBcECgwIzs7+5z3/dnPftaIkwBoaF27dj2n/Twej/7+97838jRoDggUAABgDh8zhlkff/yxfvGLX2jIkCH65ptvJEkvvviiNm7c6PJkABpCVVWV9uzZo9OnT7s9CgwiUGDSm2++qcTERLVu3Vrbtm1TZWWlJKm0tFRPPvmky9MBqI+TJ08qKSlJbdq0Ud++fVVQUCBJmjFjhp566imXp4MVBApMmjt3rjIyMvT888/7fCX70KFDtW3bNhcnA1Bfqamp2r59u9avX6+LLrrIuz4hIUGvvfaai5PBklZuDwCczZ49ezR8+PAz1oeGhqqkpKTpBwLQYFatWqXXXntNgwcP9vnkXt++fZWfn+/iZLCEMygwKSoqSvv27Ttj/caNG73f4QGgeTp27JgiIiLOWF9RUfGTtxrAhYNAgUlTp07Vvffeq9zcXHk8HhUWFuqll17S/fffr2nTprk9HoB6GDhwoN59913v4++j5M9//rPi4uLcGgvG8BYPTHr44YdVW1ur+Ph4nTx5UsOHD1dQUJAeeOABTZkyxe3xANTDk08+qZEjR+pvf/ubTp8+rWeeeUZ/+9vftHnz5jrdDwktG2dQYJLH49H//u//qri4WF9++aW2bNmiY8eOKTQ09Jxv+ATApmHDhmn79u06ffq0+vXrpw8++EARERHKycnRgAED3B4PRnAGBaZUVlbqscce09q1a71nTMaOHaulS5dq3Lhx8vf318yZM90eE8B5qq6u1n//93/r0Ucf1fPPP+/2ODCMO8nClIceekh//OMflZCQoM2bN+vYsWOaPHmytmzZov/5n//RhAkT5O/v7/aYAOohNDRUn3/+OWdD8aN4iwemrFixQsuXL9cbb7yhDz74QDU1NTp9+rS2b9+uiRMnEidACzB27FitWrXK7TFgHG/xwJRDhw5534O+4oorFBQUpJkzZ/LRQ6AF6dGjh5544glt2rRJAwYMUHBwsM92vs0YEm/xwBh/f38VFRWpQ4cOkqS2bdvqiy++4FQw0IL82O8z32aM7xEoMMXPz08jR45UUFCQJGn16tW64YYbzvgX1sqVK90YDwDQRHiLB6bceeedPo9/8YtfuDQJAMBNnEEBADSpmpoaZWZmKisrS0ePHlVtba3P9nXr1rk0GSzhDAoAoEnde++9yszM1OjRo3XFFVdwETzOijMoAIAmdckll2j58uUaNWqU26PAMO6DAgBoUoGBgerevbvbY8A4AgUA0KTuv/9+PfPMM+IEPn4Mb/EAAJrUuHHj9NFHHyk8PFx9+/ZVQECAz3ZuIwCJi2QBAE0sLCxM48aNc3sMGMcZFAAAYA5nUAAATaJdu3Zn/UhxaGioYmNjNWvWLN14440uTAaLOIMCAGgSy5YtO+v6kpIS5eXl6bXXXtMbb7yhMWPGNPFksIhAAQCYkJaWpjfeeEObN292exQYQKAAAEz46quvNHjwYBUXF7s9CgzgPigAABMqKysVGBjo9hgwgkABAJjwl7/8RVdffbXbY8AIPsUDAGgSKSkpZ11fWlqqbdu26auvvtKGDRuaeCpYRaAAAJrEZ599dtb1ISEhuvHGG7Vy5Up17dq1iaeCVVwkCwAAzOEaFAAAYA6BAgAAzCFQAACAOQQKAAAwh0AB8KOKioo0Y8YMdevWTUFBQYqJidGYMWOUlZV1Ts/PzMxUWFhY4w4JoMXhY8YAftDXX3+toUOHKiwsTAsWLFC/fv1UXV2t999/X8nJydq9e7fbI9ZZdXW1AgIC3B4DwE/gDAqAH/Sb3/xGHo9HW7du1fjx4xUbG6u+ffsqJSVFW7ZskfTdF7z169dPwcHBiomJ0W9+8xuVl5dLktavX6/JkyertLRUHo9HHo9Hjz32mKTvbms+a9YsderUScHBwRo0aJDWr1/v8/Off/55xcTEqE2bNho3bpzS0tLOOBuzZMkSXX755QoMDFTPnj314osv+mz3eDxasmSJbr75ZgUHB2vu3Lnq3r27nn76aZ/9Pv/8c3k8Hu3bt6/h/gIBnD8HAM7i+PHjjsfjcZ588skf3W/hwoXOunXrnP379ztZWVlOz549nWnTpjmO4ziVlZXOokWLnJCQEOfw4cPO4cOHnRMnTjiO4zhTpkxxhgwZ4mzYsMHZt2+fs2DBAicoKMj56quvHMdxnI0bNzp+fn7OggULnD179jjp6elOeHi4Exoa6v3ZK1eudAICApz09HRnz549zu9//3vH39/fWbdunXcfSU5ERITzwgsvOPn5+c6BAwec3/72t06fPn18Xsc999zjDB8+vCH+6gA0AAIFwFnl5uY6kpyVK1fW6XkrVqxw2rdv7328dOlSn6hwHMc5cOCA4+/v73zzzTc+6+Pj453U1FTHcRzn1ltvdUaPHu2zfdKkST7HGjJkiDN16lSffSZMmOCMGjXK+1iSc9999/ns88033zj+/v5Obm6u4ziOU1VV5VxyySVOZmZmnV4rgMbDWzwAzso5x5tMf/jhh4qPj1enTp3Utm1b3XHHHTp+/LhOnjz5g8/ZsWOHampqFBsbq4svvti7ZGdnKz8/X5K0Z88eXXPNNT7P+9fHu3bt0tChQ33WDR06VLt27fJZN3DgQJ/H0dHRGj16tF544QVJ0urVq1VZWakJEyac02sG0Pi4SBbAWfXo0UMej+dHL4T9+uuv9fOf/1zTpk3Tb3/7W4WHh2vjxo1KSkpSVVWV2rRpc9bnlZeXy9/fX3l5efL39/fZdvHFFzfo65Ck4ODgM9ZNmTJFd9xxhxYuXKilS5fq1ltv/cF5ATQ9zqAAOKvw8HAlJiYqPT1dFRUVZ2wvKSlRXl6eamtr9fvf/16DBw9WbGysCgsLffYLDAxUTU2Nz7r+/furpqZGR48eVffu3X2WqKgoSVLPnj31ySef+DzvXx/37t1bmzZt8lm3adMm9enT5ydf36hRoxQcHKwlS5ZozZo1+tWvfvWTzwHQdAgUAD8oPT1dNTU1uuaaa/Tmm29q79692rVrlxYvXqy4uDh1795d1dXVevbZZ/X3v/9dL774ojIyMnyO0aVLF5WXlysrK0vffvutTp48qdjYWE2aNEm//OUvtXLlSu3fv19bt27VvHnz9O6770qSZsyYob/+9a9KS0vT3r179cc//lHvvfeePB6P99gPPPCAMjMztWTJEu3du1dpaWlauXKlZs2a9ZOvzd/fX3fddZdSU1PVo0cPxcXFNexfHoD6cfsiGAC2FRYWOsnJyc5ll13mBAYGOp06dXJuvvlm56OPPnIcx3HS0tKcjh07Oq1bt3YSExOd5cuXO5Kcf/zjH95j/PrXv3bat2/vSHLmzJnjOM53F6bOnj3b6dKlixMQEOB07NjRGTdunPPFF194n/enP/3J6dSpk9O6dWtn7Nixzty5c52oqCif+Z577jmnW7duTkBAgBMbG+ssX77cZ7sk56233jrra8vPz3ckOfPnz6/33xOAhuVxnHO8Eg4AXDZ16lTt3r1bH3/8cYMc7+OPP1Z8fLwOHjyoyMjIBjkmgIbBRbIAzHr66ad14403Kjg4WO+9956WLVum5557rt7Hrays1LFjx/TYY49pwoQJxAlgENegADBr69atuvHGG9WvXz9lZGRo8eLFmjJlSr2P+8orr+iyyy5TSUmJ5s+f3wCTAmhovMUDAADM4QwKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAw5/8Bh86E7BYc8kYAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.groupby(['Category']).size().plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSs6K8UGe57V",
        "outputId": "dd32dafb-ec7f-4a1c-bb92-f1235a28f7d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "TqVv3Y6HTv4e"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sen):\n",
        "    # Change into a string the input\n",
        "    # sen = str(sen)\n",
        "    \n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "nXCS3K65VOhf"
      },
      "outputs": [],
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "kijEP3jRgw2o"
      },
      "outputs": [],
      "source": [
        "emails = []\n",
        "sentences = list(df[\"Emails\"])\n",
        "for sen in sentences:\n",
        "  emails.append(preprocess_text(sen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "ype9jhBBVz-v"
      },
      "outputs": [],
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "labels = {'Related': 0,\n",
        "          'Unrelated': 1\n",
        "          }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['Category']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['Emails']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "aehAtE7lTTyZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXwl5vqcW1cS",
        "outputId": "0e74c1af-f031-46a0-c02c-1ed6417c5cf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "228 29 29\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))\n",
        "print(type(df_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngOFeFWATUcd",
        "outputId": "3bb8378d-f8fb-463f-ec62-f597a3f60370"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 114/114 [20:53<00:00, 10.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Train Loss:  0.773                 | Train Accuracy:  0.303                 | Val Loss:  0.661                 | Val Accuracy:  0.552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [20:27<00:00, 10.77s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 2 | Train Loss:  0.579                 | Train Accuracy:  0.684                 | Val Loss:  0.485                 | Val Accuracy:  0.828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [20:30<00:00, 10.79s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 3 | Train Loss:  0.444                 | Train Accuracy:  0.781                 | Val Loss:  0.342                 | Val Accuracy:  0.862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [20:30<00:00, 10.79s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 4 | Train Loss:  0.348                 | Train Accuracy:  0.794                 | Val Loss:  0.225                 | Val Accuracy:  0.966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [20:28<00:00, 10.78s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 5 | Train Loss:  0.273                 | Train Accuracy:  0.864                 | Val Loss:  0.184                 | Val Accuracy:  0.897\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "                  \n",
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "              \n",
        "train(model, df_train, df_val, LR, EPOCHS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "XFilxVIsVFZq"
      },
      "outputs": [],
      "source": [
        "# # Save the entire model as a `.keras` zip archive.\n",
        "# model.save('model.keras')\n",
        "\n",
        "# model1 = tf.keras.models.load_model('model.keras')\n",
        "\n",
        "# # Show the model architecture\n",
        "# model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-054W1fXod0",
        "outputId": "94564e0d-adde-4cf0-c31e-b3ea46d93f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.724\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    y_preds = []\n",
        "    y_trues = []\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "\n",
        "              y_trues.append(test_label)\n",
        "\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "              y_preds.append(output.argmax(dim=1))\n",
        "\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "    \n",
        "    # confusion_matrix = metrics.confusion_matrix(y_trues, y_preds, labels=[\"Related\", \"Unrelated\"])\n",
        "    # print(confusion_matrix)\n",
        "    \n",
        "evaluate(model, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "TFD3GyX1xH9r"
      },
      "outputs": [],
      "source": [
        "# y_preds = []\n",
        "# y_trues = []\n",
        "\n",
        "# for index,val_text in enumerate(val_texts):\n",
        "#      tokenized_val_text = tokenizer([val_text], \n",
        "#                                     truncation=True,\n",
        "#                                     padding=True,\n",
        "#                                     return_tensor='pt')\n",
        "#      logits = model(tokenized_val_text)\n",
        "#      prediction = F.softmax(logits, dim=1)\n",
        "#      y_pred = torch.argmax(prediction).numpy()\n",
        "#      y_true = val_labels[index]\n",
        "#      y_preds.append(y_pred)\n",
        "#      y_trues.append(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "iIrU0B74ikGt"
      },
      "outputs": [],
      "source": [
        "def preprocessing(input_text, tokenizer):\n",
        "  return tokenizer.encode_plus(input_text, \n",
        "                               add_special_tokens = True,\n",
        "                               max_length = 512,\n",
        "                               padding='longest',\n",
        "                               return_attention_mask = True,\n",
        "                               return_tensors = 'pt'\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "S-aVgRMrffr_"
      },
      "outputs": [],
      "source": [
        "def predict(model, userinput):\n",
        "  input_ids = []\n",
        "  attention_mask = []\n",
        "  encoding = preprocessing(userinput, tokenizer)\n",
        "\n",
        "  input_ids.append(encoding['input_ids'])\n",
        "  attention_mask.append(encoding['attention_mask'])\n",
        "  input_ids = torch.cat(input_ids, dim = 0)\n",
        "  attention_mask = torch.cat(attention_mask, dim = 0)\n",
        "\n",
        "  output = model(input_ids, attention_mask)\n",
        "  prediction = 'Related' if np.argmax(output.detach().numpy()).flatten()==0 else 'Unrelated'\n",
        "  # print(\"Tensor is: \", output.argmax(dim=1))\n",
        "  print(\"This message is: \", prediction)\n",
        "\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q0cD8wnfFLl"
      },
      "source": [
        "PART 2: EVENT EXTRACTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx9EWrc8_Izf"
      },
      "source": [
        "Training the Stanford NLP Tagger Using our own training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpoV3QuoEFlq",
        "outputId": "d7d08562-4948-4b1a-a8b3-ad8f1fb855df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exit code: 0\n",
            "Error output: Invoked on Mon Jun 05 20:18:30 UTC 2023 with arguments: -prop /content/ner-training.prop\n",
            "useTypeSeqs2=true\n",
            "noMidNGrams=true\n",
            "useWordPairs=true\n",
            "trainFile=/content/CS72 Project_Emails_training_dataset_StanfordNER - Sheet1.tsv\n",
            "maxLeft=1\n",
            "serializeTo=/content/ner-model.ser.gz\n",
            "wordShape=chris2useLC\n",
            "useWordTag=true\n",
            "useDisjunctive=true\n",
            "useOccurrencePatterns=true\n",
            "useClassFeature=true\n",
            "useNGrams=true\n",
            "useNext=true\n",
            "usePrev=true\n",
            "useGazettes=true\n",
            "useTypeySequences=true\n",
            "useSymTags=True\n",
            "usePrevSequences=true\n",
            "useTypeSeqs=true\n",
            "useSequences=true\n",
            "map=word=0,answer=1\n",
            "useWord=true\n",
            "useShapeConjunctions=True\n",
            "numFeatures = 7470\n",
            "Time to convert docs to feature indices: 0.2 seconds\n",
            "Current memory used: 4m\n",
            "numClasses: 6 [0=O,1=0,2=DATE,3=TIME,4=PERSON,5=LOCATION]\n",
            "numDocuments: 1\n",
            "numDatums: 430\n",
            "numFeatures: 7470\n",
            "Time to convert docs to data/labels: 0.1 seconds\n",
            "Current memory used: 8m\n",
            "Running gradient on 2 threads\n",
            "numWeights: 82890\n",
            "QNMinimizer called on double function of 82890 variables, using M = 25.\n",
            "               An explanation of the output:\n",
            "Iter           The number of iterations\n",
            "evals          The number of function evaluations\n",
            "SCALING        <D> Diagonal scaling was used; <I> Scaled Identity\n",
            "LINESEARCH     [## M steplength]  Minpack linesearch\n",
            "                   1-Function value was too high\n",
            "                   2-Value ok, gradient positive, positive curvature\n",
            "                   3-Value ok, gradient negative, positive curvature\n",
            "                   4-Value ok, gradient negative, negative curvature\n",
            "               [.. B]  Backtracking\n",
            "VALUE          The current function value\n",
            "TIME           Total elapsed time\n",
            "|GNORM|        The current norm of the gradient\n",
            "{RELNORM}      The ratio of the current to initial gradient norms\n",
            "AVEIMPROVE     The average improvement / current value\n",
            "EVALSCORE      The last available eval score\n",
            " \n",
            "Iter ## evals ## <SCALING> [LINESEARCH] VALUE TIME |GNORM| {RELNORM} AVEIMPROVE EVALSCORE\n",
            "\n",
            "Iter 1 evals 1 <D> [M 1.000E-1] 1.257E4 0.11s |2.010E2| {4.538E-1} 0.000E0 - \n",
            "Iter 2 evals 2 <D> [M 1.000E0] 9.785E3 0.17s |1.713E2| {3.867E-1} 1.425E-1 - \n",
            "Iter 3 evals 3 <D> [M 1.000E0] 5.178E3 0.20s |3.307E2| {7.467E-1} 4.761E-1 - \n",
            "Iter 4 evals 4 <D> [M 1.000E0] 2.897E3 0.24s |9.498E1| {2.144E-1} 8.349E-1 - \n",
            "Iter 5 evals 5 <D> [M 1.000E0] 1.797E3 0.28s |7.900E1| {1.783E-1} 1.200E0 - \n",
            "Iter 6 evals 6 <D> [M 1.000E0] 1.389E3 0.32s |1.082E2| {2.443E-1} 1.342E0 - \n",
            "Iter 7 evals 7 <D> [M 1.000E0] 9.260E2 0.36s |4.976E1| {1.123E-1} 1.797E0 - \n",
            "Iter 8 evals 8 <D> [M 1.000E0] 4.366E2 0.40s |5.251E1| {1.185E-1} 3.475E0 - \n",
            "Iter 9 evals 9 <D> [M 1.000E0] 3.530E2 0.44s |3.009E1| {6.793E-2} 3.846E0 - \n",
            "Iter 10 evals 10 <D> [2M 5.195E-1] 2.621E2 0.51s |4.068E1| {9.184E-2} 4.697E0 - \n",
            "Iter 11 evals 12 <D> [1M 3.267E-1] 1.798E2 0.60s |5.125E1| {1.157E-1} 5.343E0 - \n",
            "Iter 12 evals 14 <D> [M 1.000E0] 1.333E2 0.65s |2.281E1| {5.148E-2} 3.783E0 - \n",
            "Iter 13 evals 15 <D> [M 1.000E0] 1.028E2 0.71s |2.497E1| {5.638E-2} 2.719E0 - \n",
            "Iter 14 evals 16 <D> [1M 3.737E-1] 7.077E1 0.79s |1.306E1| {2.949E-2} 2.439E0 - \n",
            "Iter 15 evals 18 <D> [1M 4.563E-1] 6.068E1 0.84s |1.517E1| {3.425E-2} 2.190E0 - \n",
            "Iter 16 evals 20 <D> [M 1.000E0] 4.829E1 0.87s |1.733E1| {3.913E-2} 1.817E0 - \n",
            "Iter 17 evals 21 <D> [M 1.000E0] 4.292E1 0.89s |1.598E1| {3.608E-2} 9.173E-1 - \n",
            "Iter 18 evals 22 <D> [M 1.000E0] 3.981E1 0.92s |6.634E0| {1.498E-2} 7.866E-1 - \n",
            "Iter 19 evals 23 <D> [M 1.000E0] 3.785E1 0.94s |6.338E0| {1.431E-2} 5.925E-1 - \n",
            "Iter 20 evals 24 <D> [M 1.000E0] 3.496E1 0.96s |5.835E0| {1.317E-2} 4.142E-1 - \n",
            "Iter 21 evals 25 <D> [M 1.000E0] 3.319E1 0.99s |3.922E0| {8.855E-3} 3.017E-1 - \n",
            "Iter 22 evals 26 <D> [M 1.000E0] 3.165E1 1.01s |3.833E0| {8.654E-3} 2.247E-1 - \n",
            "Iter 23 evals 27 <D> [M 1.000E0] 3.123E1 1.04s |3.640E0| {8.218E-3} 1.266E-1 - \n",
            "Iter 24 evals 28 <D> [M 1.000E0] 3.096E1 1.07s |1.311E0| {2.960E-3} 9.595E-2 - \n",
            "Iter 25 evals 29 <D> [M 1.000E0] 3.083E1 1.09s |8.451E-1| {1.908E-3} 5.666E-2 - \n",
            "Iter 26 evals 30 <D> [M 1.000E0] 3.075E1 1.12s |6.273E-1| {1.416E-3} 3.954E-2 - \n",
            "Iter 27 evals 31 <D> [M 1.000E0] 3.073E1 1.14s |2.940E-1| {6.638E-4} 2.957E-2 - \n",
            "Iter 28 evals 32 <D> [M 1.000E0] 3.072E1 1.17s |2.828E-1| {6.385E-4} 2.322E-2 - \n",
            "Iter 29 evals 33 <D> [M 1.000E0] 3.071E1 1.19s |1.634E-1| {3.688E-4} 1.384E-2 - \n",
            "Iter 30 evals 34 <D> [M 1.000E0] 3.071E1 1.21s |9.691E-2| {2.188E-4} 8.071E-3 - \n",
            "Iter 31 evals 35 <D> [M 1.000E0] 3.071E1 1.23s |8.674E-2| {1.958E-4} 3.041E-3 - \n",
            "Iter 32 evals 36 <D> [M 1.000E0] 3.071E1 1.25s |3.397E-2| {7.670E-5} 1.695E-3 - \n",
            "Iter 33 evals 37 <D> [M 1.000E0] 3.071E1 1.27s |2.399E-2| {5.416E-5} 8.216E-4 - \n",
            "Iter 34 evals 38 <D> [M 1.000E0] 3.071E1 1.29s |2.017E-2| {4.553E-5} 3.678E-4 - \n",
            "Iter 35 evals 39 <D> [M 1.000E0] 3.071E1 1.31s |1.003E-2| {2.265E-5} 1.376E-4 - \n",
            "QNMinimizer terminated due to average improvement: | newest_val - previous_val | / |newestVal| < TOL \n",
            "Total time spent in optimization: 1.33s\n",
            "CRFClassifier training ... done [1.9 sec].\n",
            "Serializing classifier to /content/ner-model.ser.gz... done.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "jar_path = \"/content/stanford-ner.jar\"\n",
        "prop_file = \"/content/ner-training.prop\"\n",
        "\n",
        "command = f\"java -cp {jar_path} edu.stanford.nlp.ie.crf.CRFClassifier -prop {prop_file}\"\n",
        "\n",
        "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "\n",
        "print(\"Exit code:\", result.returncode)\n",
        "print(\"Error output:\", result.stderr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGoXCdyX78Sk"
      },
      "source": [
        "Tokenize the text and assign labels (i.e DATE, LOCATION, PERSON, etc) to formed tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "rf313o7pTUmm"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "def testStanfordNERTTagger(text):\n",
        "\tst = StanfordNERTagger('/content/ner-model.ser.gz',\n",
        "\t\t\t\t\t\t\t'/content/stanford-ner.jar',\n",
        "\t\t\t\t\t\t\tencoding='utf-8')\n",
        "\n",
        "\ttokenized_text = word_tokenize(text)\n",
        "\tclassified_text = st.tag(tokenized_text)\n",
        "\n",
        "\treturn classified_text\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_l9qO5-StID"
      },
      "source": [
        "USING GMAIL API TO ACCESS ONE'S EMAILS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I0bEk0rSSpS",
        "outputId": "75f5c1ad-7d5c-4234-8a65-576b78f07d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.88.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.21.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "6djen7U2ztu6"
      },
      "outputs": [],
      "source": [
        "#Get credentials from gmail API(jackline.w.gathoni.24@dartmouth.edu)\n",
        "from __future__ import print_function\n",
        "\n",
        "import os.path\n",
        "\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "# If modifying these scopes, delete the file token.json.\n",
        "SCOPES = ['https://www.googleapis.com/auth/gmail.modify']\n",
        "\n",
        "\n",
        "def getService():\n",
        "    \"\"\"Shows basic usage of the Gmail API.\n",
        "    Lists the user's Gmail labels.\n",
        "    \"\"\"\n",
        "    creds = None\n",
        "    # The file token.json stores the user's access and refresh tokens, and is\n",
        "    # created automatically when the authorization flow completes for the first\n",
        "    # time.\n",
        "    if os.path.exists('gmail_token.json'):\n",
        "        creds = Credentials.from_authorized_user_file('gmail_token.json', SCOPES)\n",
        "    # If there are no (valid) credentials available, let the user log in.\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                'credentials.json', SCOPES)\n",
        "            creds = flow.run_local_server(port=0)\n",
        "        # Save the credentials for the next run\n",
        "        with open('gmail_token.json', 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "\n",
        "    try:\n",
        "        # Call the Gmail API\n",
        "        service = build('gmail', 'v1', credentials=creds)\n",
        "        return service\n",
        "\n",
        "    except HttpError as error:\n",
        "        # TODO(developer) - Handle errors from gmail API.\n",
        "        print(f'An error occurred: {error}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4iQ_SsUmncg",
        "outputId": "16b7c13a-8a45-4203-e745-8497c864ca51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The deets include: {'Subject': 'Re: Info Extraction and ASR', 'Sender': 'Ryan Dudak <ryan.a.dudak.24@dartmouth.edu>', 'Message': 'Re: Info Extraction and ASR \\nHi Jackline,\\r\\n\\r\\nYour chatbot does not respond correctly to certain questions related to\\r\\nordering pizza. For example, when asked \"Can I have a pizza with ham and\\r\\npineapple?\" your chatbot responds \"Sure! What toppings would you like on\\r\\nyour pizza?\" which is not an intuitive or expected response since the user\\r\\njust provided the toppings in the previous message. I hope that makes\\r\\nsense, but please let me know if you have any other questions.\\r\\n\\r\\nCheers,\\r\\nRyan\\r\\n\\r\\nOn Mon, Jun 5, 2023 at 4:23 PM Jackline Gathoni <\\r\\njackline.w.gathoni.24@dartmouth.edu> wrote:\\r\\n\\r\\n> Hey Ryan,\\r\\n>\\r\\n> I am a bit confused by your feedback. The chatbot seems to be working fine\\r\\n> on my end, as per the screenshots submitted. Could you clarify what you\\r\\n> meant by \"Ordering pizza interaction is not very smooth\"\\r\\n>\\r\\n> Thank you,\\r\\n> Jackline\\r\\n>\\r\\n-- \\r\\nBest,\\r\\nRyan Dudak\\r\\n', 'Recipients': 'Jackline Gathoni <jackline.w.gathoni.24@dartmouth.edu>'}\n"
          ]
        }
      ],
      "source": [
        "# Reads incoming emails to check if theyre related to shift-dropping or not and then parse for relevant info(date, time and location).\n",
        "import base64\n",
        "service =getService()\n",
        "\n",
        "def getEmails(service):\n",
        "    email_details={}\n",
        "    # to read new messages, get unread specifically,  # add check for no new messages if you decide to do unread messages only\n",
        "    # results = service.users().messages().list(userId=\"me\", labelIds=[\"INBOX\"], q=\"from:specific email, is:unread\").execute()\n",
        "    results = service.users().messages().list(maxResults=1, userId='me', labelIds=[\"INBOX\"]).execute()\n",
        "\n",
        "   \n",
        "    messages = results.get('messages')  # messages is a list of dictionaries where each dictionary contains a message id.\n",
        "  \n",
        "   \n",
        "    # iterate through all the messages\n",
        "    for msg in messages:\n",
        "        # Get the message from its id\n",
        "        txt = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
        "  \n",
        "        # Use try-except to avoid any Errors\n",
        "        try:\n",
        "            # Get value of 'payload' from dictionary 'txt'\n",
        "         \n",
        "            payload = txt['payload']\n",
        "            headers = payload['headers']\n",
        "            parts = payload.get('parts')\n",
        "         \n",
        "  \n",
        "            # Look for Subject, Sender Email and other Recipient emails in the headers\n",
        "            for d in headers:\n",
        "                if d['name'] == 'Subject':\n",
        "                    subject = d['value']\n",
        "                if d['name'] == 'From':\n",
        "                    sender = d['value']\n",
        "                if d['name'] == 'To':\n",
        "                    recipient = d['value']\n",
        "                \n",
        "  \n",
        "            # from stacksoiverflow to decode the body into plain text\n",
        "            for part in parts:\n",
        "                if part[\"mimeType\"] in [\"text/plain\"]:\n",
        "                    data = base64.urlsafe_b64decode(part[\"body\"][\"data\"]).decode(\"utf-8\")\n",
        "                   \n",
        "\n",
        "            #add parts of the email to the email dictionary to be used in sending an automated response when available\n",
        "            email_details[\"Subject\"]=subject\n",
        "            email_details[\"Sender\"]= sender\n",
        "            email_details[\"Message\"]= subject +' \\n' + data  #adds the subject to the body of the email in case the subject contains relevant information\n",
        "            email_details[\"Recipients\"]= recipient\n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "    return email_details\n",
        "  \n",
        "  \n",
        "print(\"The deets include:\" ,getEmails(service))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSMmjsvBse_Y",
        "outputId": "1c7ea218-ecde-48f9-e92c-a93200007605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The deets include: {'Subject': 'Re: Info Extraction and ASR', 'Sender': 'Ryan Dudak <ryan.a.dudak.24@dartmouth.edu>', 'Message': 'Hi Jackline,\\r\\n\\r\\nYour chatbot does not respond correctly to certain questions related to\\r\\nordering pizza. For example, when asked \"Can I have a pizza with ham and\\r\\npineapple?\" your chatbot responds \"Sure! What toppings would you like on\\r\\nyour pizza?\" which is not an intuitive or expected response since the user\\r\\njust provided the toppings in the previous message. I hope that makes\\r\\nsense, but please let me know if you have any other questions.\\r\\n\\r\\nCheers,\\r\\nRyan\\r\\n\\r\\nOn Mon, Jun 5, 2023 at 4:23 PM Jackline Gathoni <\\r\\njackline.w.gathoni.24@dartmouth.edu> wrote:\\r\\n\\r\\n> Hey Ryan,\\r\\n>\\r\\n> I am a bit confused by your feedback. The chatbot seems to be working fine\\r\\n> on my end, as per the screenshots submitted. Could you clarify what you\\r\\n> meant by \"Ordering pizza interaction is not very smooth\"\\r\\n>\\r\\n> Thank you,\\r\\n> Jackline\\r\\n>\\r\\n-- \\r\\nBest,\\r\\nRyan Dudak\\r\\n', 'Recipients': 'Jackline Gathoni <jackline.w.gathoni.24@dartmouth.edu>'}\n"
          ]
        }
      ],
      "source": [
        "# Reads incoming emails to check if theyre related to shift-dropping or not and then parse for relevant info(date, time and location).\n",
        "import base64\n",
        "service =getService()\n",
        "\n",
        "def getEmails(service):\n",
        "    email_details={}\n",
        "    # to read new messages, get unread specifically\n",
        "    # results = service.users().messages().list(userId=\"me\", labelIds=[\"INBOX\"], q=\"from:specific email, is:unread\").execute()\n",
        "    results = service.users().messages().list(maxResults=1, userId='me', labelIds=[\"INBOX\"]).execute()\n",
        "\n",
        "    # add check for no new messages if you decide to do unread messages only\n",
        "    messages = results.get('messages')\n",
        "  \n",
        "    # messages is a list of dictionaries where each dictionary contains a message id.\n",
        "  \n",
        "    # iterate through all the messages\n",
        "    for msg in messages:\n",
        "        # Get the message from its id\n",
        "        txt = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
        "  \n",
        "        # Use try-except to avoid any Errors\n",
        "        try:\n",
        "            # Get value of 'payload' from dictionary 'txt'\n",
        "            payload = txt['payload']\n",
        "            headers = payload['headers']\n",
        "            # parts = payload.get('parts')[0] #-> could be some source of error\n",
        "            parts = payload.get('parts')\n",
        "  \n",
        "            # Look for Subject and Sender Email in the headers\n",
        "            for d in headers:\n",
        "                if d['name'] == 'Subject':\n",
        "                    subject = d['value']\n",
        "                if d['name'] == 'From':\n",
        "                    sender = d['value']\n",
        "            \n",
        "                if d['name'] == 'To':\n",
        "                    recipient = d['value']\n",
        "  \n",
        "            # from stacksoiverflow to decode the body into plain text\n",
        "            for part in parts:\n",
        "                if part[\"mimeType\"] in [\"text/plain\"]:\n",
        "                    data = base64.urlsafe_b64decode(part[\"body\"][\"data\"]).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "            # Printing the subject, sender's email and message\n",
        "            # print(\"Subject: \", subject)\n",
        "            # print('\\n')\n",
        "            # print(\"From: \", sender)\n",
        "            # print('\\n')\n",
        "            # print(\"Message: \", data)\n",
        "            # print('\\n')\n",
        "\n",
        "            email_details[\"Subject\"]=subject\n",
        "            email_details[\"Sender\"]= sender\n",
        "            email_details[\"Message\"]= data\n",
        "            email_details[\"Recipients\"]= recipient\n",
        "        \n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "    return email_details\n",
        "  \n",
        "  \n",
        "print(\"The deets include:\" ,getEmails(service))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teGb24uc8KwP"
      },
      "source": [
        "Test the BERT Classifier and StanfordNER Model a single email from the gmail account: jackline.w.gathoni.24@dartmouth.edu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY_tVlmCeiTP",
        "outputId": "3360b05e-8c6a-4feb-eb36-c32693e9f599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write in a test message: Can someone take my baker shift from noon ?\n",
            "This message is:  Related\n",
            "[('Can', '0'), ('someone', '0'), ('take', '0'), ('my', '0'), ('baker', '0'), ('shift', '0'), ('from', '0'), ('noon', '0'), ('?', '0')]\n"
          ]
        }
      ],
      "source": [
        "# userinput = input(\"\\nPut in a test sentence: \\n\")\n",
        "\n",
        "# email_details = getEmails(service)\n",
        "# userinput = email_details[\"Message\"]\n",
        "userinput = input(\"Write in a test message: \")\n",
        "pred = predict(model, userinput)\n",
        "\n",
        "if(pred == 'Related'):\n",
        "  classified_text = testStanfordNERTTagger(userinput)\n",
        "  print(classified_text)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFHaqu8STGog"
      },
      "source": [
        "SCHEDULING: CHECKING ONE'S GOOGLE CALENDAR TO VERIFY IF THEY ARE AVAILABLE FOR THE DROPPED SHIFT TIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5POK2Wtffn0",
        "outputId": "5d574ff6-5f5d-404b-a211-1afbaba1ee77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parsed start 00:00:00\n",
            "parsed end 02:00:00\n",
            "Getting the upcoming 10 events\n",
            "Wozzah\n"
          ]
        }
      ],
      "source": [
        "# start_time = datetime.time(hour=2, minute=0, second=0, tzinfo= ZoneInfo('US/Eastern'))\n",
        "# end_time = datetime.time(hour=3, minute=0, second=0,tzinfo= ZoneInfo('US/Eastern'))\n",
        "\n",
        "test=[(\"midnight-2\", \"TIME\")] \n",
        "# result = getTime(classified_text)\n",
        "result = getTime(test)\n",
        "start_time = None\n",
        "end_time = None\n",
        "\n",
        "if result != None:\n",
        "  start_time = result[0]\n",
        "  end_time = result[1]\n",
        "  print(\"parsed start\",start_time)\n",
        "  print(\"parsed end\",end_time)\n",
        "  available = checkAvailability(start_time, end_time)\n",
        "\n",
        "  if available:\n",
        "    print(\"Wozzah\")\n",
        "    # test send email\n",
        "    # send_message(service, destination, emailDetails[\"Subject\"], \n",
        "    #             \"I can\",\n",
        "    # )\n",
        "\n",
        "else:\n",
        "  print(\"INVALID TIME FORMAT!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OII52W7OSYG5",
        "outputId": "6af6eb36-8fcf-425d-d996-4afbcdd8decc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2022.7.1)\n"
          ]
        }
      ],
      "source": [
        "pip install pytz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47g3Oh3mSYKF",
        "outputId": "f5b61948-92c3-43f9-d63d-3e11714e24d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.88.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.21.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "ghdIaT7RbYww"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import os.path\n",
        "import pytz\n",
        "\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "\n",
        "# If modifying these scopes, delete the file token.json.\n",
        "SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
        "\n",
        "\n",
        "def getEvents():\n",
        "    \"\"\"Shows basic usage of the Google Calendar API.\n",
        "    Prints the start and name of the next 10 events on the user's calendar.\n",
        "    \"\"\"\n",
        "    creds = None\n",
        "    # The file token.json stores the user's access and refresh tokens, and is\n",
        "    # created automatically when the authorization flow completes for the first\n",
        "    # time.\n",
        "    if os.path.exists('calendar_token.json'):\n",
        "        creds = Credentials.from_authorized_user_file('calendar_token.json', SCOPES)\n",
        "    # If there are no (valid) credentials available, let the user log in.\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                './client_secret_241823786615-5oh4q20ihegr14g6bpst89ke47v65ikf.apps.googleusercontent.com.json', SCOPES)\n",
        "            creds = flow.run_local_server(port=0)\n",
        "        # Save the credentials for the next run\n",
        "        with open('calendar_token.json', 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "\n",
        "    try:\n",
        "        service = build('calendar', 'v3', credentials=creds)\n",
        "\n",
        "        # Call the Calendar API\n",
        "        now = datetime.datetime.utcnow().isoformat() + 'Z'  # 'Z' indicates UTC time\n",
        "        print('Getting the upcoming 10 events')\n",
        "        events_result = service.events().list(calendarId='primary', timeMin=now,\n",
        "                                              maxResults=10, singleEvents=True,\n",
        "                                              orderBy='startTime').execute()\n",
        "        events = events_result.get('items', [])\n",
        "\n",
        "        if not events:\n",
        "            print('No upcoming events found.')\n",
        "            return\n",
        "\n",
        "        # Prints the start and name of the next 10 events\n",
        "    \n",
        "    except HttpError as error:\n",
        "        print('An error occurred: %s' % error)\n",
        "    return events\n",
        "\n",
        "\n",
        "def parseDate(rawDate):\n",
        "    #Transform the datetime given by the API to a python datetime object.\n",
        "    return datetime.datetime.strptime(rawDate[:-6]+ rawDate[-6:].replace(\":\",\"\"), '%Y-%m-%dT%H:%M:%S%z')\n",
        "\n",
        "\n",
        "def checkAvailability(start_time, end_time):\n",
        "        events = getEvents()\n",
        "\n",
        "        for event in events:\n",
        "        # Define the start and end times of your desired interval\n",
        "        #Example one: non overlapping\n",
        "            \n",
        "            # start_time = datetime.time(hour=2, minute=0, second=0, tzinfo= ZoneInfo('US/Eastern'))\n",
        "            start_date= datetime.datetime.combine(datetime.datetime.today(),start_time )\n",
        "            # end_time = datetime.time(hour=3, minute=0, second=0,tzinfo= ZoneInfo('US/Eastern'))\n",
        "            end_date= datetime.datetime.combine(datetime.datetime.today(),end_time )\n",
        "\n",
        "            eventStart = parseDate(event['start'].get('dateTime', event['start'].get('date'))) \n",
        "            eventEnd = parseDate(event['end'].get('dateTime', event['end'].get('date')))\n",
        "            \n",
        "                # Check for an overlap between the event and the desired interval\n",
        "            if eventStart < end_date and eventEnd> start_date:\n",
        "                print('The desired interval overlaps with event:', event['summary'])\n",
        "                return False\n",
        "            \n",
        "        return True\n",
        "        # add to calender\n",
        "         \n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53B0J7ijdbQi"
      },
      "source": [
        "Retrieve Time from the Output of the StanfordNER Event Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "id": "I2WB6dq9coAr"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "import re\n",
        "\n",
        "def getTime(classified_text):\n",
        "  time = []\n",
        "  specialTimes={}\n",
        "  specialTimes[\"noon\"]= \"12\"\n",
        "  specialTimes[\"midnight\"]= \"00\"\n",
        "\n",
        "\n",
        "  for item in classified_text:\n",
        "    if(item[1] == 'TIME'):\n",
        "      \n",
        "      if not any(chr.isdigit() for chr in item[0]): \n",
        "        continue\n",
        "\n",
        "      #regex for parsing time\n",
        "      # expression results in five groups\n",
        "      reTime = r\"([0-9]*:*[0-9]*)(.*)(-|to)([0-9]*:*[0-9]*)(.*)\"\n",
        "      timeBreakdown = re.search(reTime, item[0], re.IGNORECASE)\n",
        "\n",
        "\n",
        "      # Group1 = start_time\n",
        "      # Group2 = am/pm/ other exceptions like noon, midnight\n",
        "      # Group3 = -/to\n",
        "      # Group4 = end_time \n",
        "      # Group5 = am/pm/other exceptions like noon, midnight\n",
        "      if timeBreakdown != None:\n",
        "        startTime = timeBreakdown.group(1)\n",
        "        startPeriod = timeBreakdown.group(2)\n",
        "        to = timeBreakdown.group(3)\n",
        "        endTime = timeBreakdown.group(4)\n",
        "        endPeriod =  timeBreakdown.group(5)\n",
        "\n",
        "\n",
        "        if startPeriod in specialTimes:\n",
        "          startTime = specialTimes[startPeriod]\n",
        "        if endPeriod in specialTimes:\n",
        "          endTime = specialTimes[endPeriod]\n",
        "\n",
        "        # if endTime == \"00\":\n",
        "        #   endTime= \"24\"\n",
        "\n",
        "\n",
        "        def splitTime(time, period):\n",
        "          timeDiv = time.split(':')\n",
        "          hours= int(timeDiv[0])\n",
        "         \n",
        "          if period == 'p' or period =='pm':\n",
        "            hours+=12\n",
        "          if len(timeDiv) == 2:\n",
        "            minutes = int(timeDiv[1])\n",
        "          else:\n",
        "            minutes = 0;\n",
        "          return hours, minutes\n",
        "     \n",
        "\n",
        "        start_time = datetime.time(splitTime(startTime, startPeriod)[0], (splitTime(startTime,startPeriod)[1]), tzinfo = ZoneInfo('US/Eastern'))\n",
        "        end_time = datetime.time(splitTime(endTime, endPeriod)[0], (splitTime(endTime, endPeriod)[1]), tzinfo = ZoneInfo('US/Eastern'))\n",
        "        return(start_time, end_time)\n",
        "\n",
        "  return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "f6v0R6LrbY5B",
        "outputId": "5f89a406-3cc3-44fb-edeb-918f4cb26665"
      },
      "outputs": [
        {
          "ename": "RefreshError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRefreshError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-288-952038421435>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Add subject to the text incase it has information about shift dropping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mreEmail\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34mr\".<(.*)>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0memailDetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetEmails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-189-81b981eb3a18>\u001b[0m in \u001b[0;36mgetEmails\u001b[0;34m(service)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# to read new messages, get unread specifically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# results = service.users().messages().list(userId=\"me\", labelIds=[\"INBOX\"], q=\"from:specific email, is:unread\").execute()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxResults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'me'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelIds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"INBOX\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# add check for no new messages if you decide to do unread messages only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# Handle retries for server-side errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         resp, content = _retry_request(\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Retry on SSL errors and socket timeout errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_ssl_SSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssl_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google_auth_httplib2.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mrequest_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# Check if the body is a file-like stream, and if so, save the body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\u001b[0m in \u001b[0;36mbefore_request\u001b[0;34m(self, request, method, url, headers)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# the http request.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/oauth2/credentials.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mgrant_response\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mrapt_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh_grant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/oauth2/reauth.py\u001b[0m in \u001b[0;36mrefresh_grant\u001b[0;34m(request, token_uri, refresh_token, client_id, client_secret, scopes, rapt_token, enable_reauth_refresh)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse_status_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_error_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretryable_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     return _client._handle_refresh_grant_response(response_data, refresh_token) + (\n\u001b[1;32m    353\u001b[0m         \u001b[0mrapt_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36m_handle_error_response\u001b[0;34m(response_data, retryable_error)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0merror_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise exceptions.RefreshError(\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0merror_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretryable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretryable_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     )\n",
            "\u001b[0;31mRefreshError\u001b[0m: ('invalid_scope: Bad Request', {'error': 'invalid_scope', 'error_description': 'Bad Request'})"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Regular expression for extracting the sender's email from sender's information: .<(.*)>\n",
        "# reEmail= r\".<(.*)>\"\n",
        "# groupEmail = re.search(reEmail, senderInfo, re.IGNORECASE)\n",
        "# destination = groupEmail\n",
        "# check that the recipient email is an email other than my specific email\n",
        "\n",
        "# Add subject to the text incase it has information about shift dropping\n",
        "reEmail= r\".<(.*)>\"\n",
        "emailDetails = getEmails(service)\n",
        "\n",
        "\n",
        "destination = re.search(reEmail, emailDetails[\"Sender\"], re.IGNORECASE).group(1)\n",
        "print(\"destination email is: \", destination)\n",
        "recipients= re.search(reEmail, emailDetails[\"Recipients\"], re.IGNORECASE)\n",
        "if recipients:\n",
        "  recipientEmail = recipients.group(1)\n",
        "print(\"other recipient email is: \", recipients)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NePdwDA-bY7z",
        "outputId": "0adc7f68-977d-4938-a62c-66d679c48127"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '1888d5cc5e6dd8f3',\n",
              " 'threadId': '1888d5cc5e6dd8f3',\n",
              " 'labelIds': ['SENT']}"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Sends email responding to the sender if available for the specific time window of the shift dropped\n",
        "\n",
        "from base64 import urlsafe_b64encode\n",
        "from email.mime.text import MIMEText\n",
        "service = getService()\n",
        "\n",
        "#think about adding recipients field for generic emails like work-place emails\n",
        "#loop through recipeints in case there's more than one\n",
        "def build_message(destination, obj, body):\n",
        "    message = MIMEText(body)\n",
        "\n",
        "    message['to'] = destination\n",
        "    message['from'] = \"jackline.w.gathoni.24@dartmouth.edu\"\n",
        "    message['subject'] = obj\n",
        "    message['In-Reply-To']= destination\n",
        "    if recipientEmail != \"jackline.w.gathoni.24@dartmouth.edu\":\n",
        "      message['References']= recipients\n",
        "\n",
        "    # message['References']= recipients\n",
        "\n",
        "    return {'raw': urlsafe_b64encode(message.as_bytes()).decode()}\n",
        "\n",
        "def send_message(service, destination, obj, body):\n",
        "    return service.users().messages().send(\n",
        "      userId=\"me\",\n",
        "      body=build_message(destination, obj, body)\n",
        "    ).execute()\n",
        "\n",
        "\n",
        "# test send email\n",
        "send_message(service, destination, emailDetails[\"Subject\"], \n",
        "                \"I can\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifrw7ogWbY1_",
        "outputId": "baac337d-ac67-40cd-c9a5-b0775beeaa7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "INVALID TIME FORMAT!\n"
          ]
        }
      ],
      "source": [
        "# start_time = datetime.time(hour=2, minute=0, second=0, tzinfo= ZoneInfo('US/Eastern'))\n",
        "# end_time = datetime.time(hour=3, minute=0, second=0,tzinfo= ZoneInfo('US/Eastern'))\n",
        "# result = getTime(classified_text)\n",
        "test =[\"10pm-midnight\",\"TIME\"]\n",
        "result = getTime(test)\n",
        "\n",
        "print(result)\n",
        "start_time = None\n",
        "end_time = None\n",
        "\n",
        "if result != None:\n",
        "  start_time = result[0]\n",
        "  end_time = result[1]\n",
        "  available = checkAvailability(start_time, end_time)\n",
        "\n",
        "  if available:\n",
        "    # test send email\n",
        "    send_message(service, destination, emailDetails[\"Subject\"], \n",
        "                \"I can\",\n",
        "    )\n",
        "\n",
        "else:\n",
        "  print(\"INVALID TIME FORMAT!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "At2Cd1uxbY_K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "lCZqsgejbZC6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "RsQU6cVHSYND"
      },
      "outputs": [],
      "source": [
        "# !python3 \"/content/work.ipynb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "Und7HtdWSYQk"
      },
      "outputs": [],
      "source": [
        "# %cd /content/tesss.ipynb\n",
        "# python3 /content/tesss.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "0ZY5NrEZx6xn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
