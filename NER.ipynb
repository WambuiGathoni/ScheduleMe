{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN3TJtIqG3Ht"
      },
      "source": [
        "***Final Project: Event Extraction *** </br>\n",
        "This program takes in related email body text and extracts the foloowing entities: time, location and name.</br>\n",
        "Dartmouth College, LING48, Spring 2023  </br>\n",
        "Jackline Gathoni Wambui (jackline.w.gathoni.24@dartmouth.edu) </br>\n",
        "Dahlia Igiraneza (dahlia.igiraneza.24@dartmouth.edu)  </br>\n",
        "Paige Nakai (paige.m.nakai.24@dartmouth.edu)  </br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "cULM_WBOHomn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/jacklinewambui/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#import neccessary packages\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.internals import find_jars_within_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0-dAPKgHwLT"
      },
      "source": [
        "Training the Stanford NLP Tagger using custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "LHsDN6UAG0ag"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exit code: 1\n",
            "Error output: Invoked on Tue Jun 06 16:11:09 EDT 2023 with arguments: -prop /Users/jacklinewambui/Desktop/finalProject/ner-training.prop\n",
            "useTypeSeqs2=true\n",
            "noMidNGrams=true\n",
            "useWordPairs=true\n",
            "trainFile=/Users/jacklinewambui/Desktop/finalProject/CS72 Project_Emails_training_dataset_StanfordNER.tsv\n",
            "maxLeft=1\n",
            "serializeTo=/Users/jacklinewambui/Desktop/finalProject/ner-model.ser.gz\n",
            "wordShape=chris2useLC\n",
            "useWordTag=true\n",
            "useDisjunctive=true\n",
            "useOccurrencePatterns=true\n",
            "useClassFeature=true\n",
            "useNGrams=true\n",
            "useNext=true\n",
            "usePrev=true\n",
            "useGazettes=true\n",
            "useTypeySequences=true\n",
            "useSymTags=True\n",
            "usePrevSequences=true\n",
            "useTypeSeqs=true\n",
            "useSequences=true\n",
            "map=word=0,answer=1\n",
            "useWord=true\n",
            "useShapeConjunctions=True\n",
            "Exception in thread \"main\" edu.stanford.nlp.io.RuntimeIOException: java.io.FileNotFoundException: /Users/jacklinewambui/Desktop/finalProject/CS72 Project_Emails_training_dataset_StanfordNER.tsv (No such file or directory)\n",
            "\tat edu.stanford.nlp.io.IOUtils.inputStreamFromFile(IOUtils.java:542)\n",
            "\tat edu.stanford.nlp.io.IOUtils.readerFromFile(IOUtils.java:577)\n",
            "\tat edu.stanford.nlp.objectbank.ReaderIteratorFactory$ReaderIterator.setNextObject(ReaderIteratorFactory.java:189)\n",
            "\tat edu.stanford.nlp.objectbank.ReaderIteratorFactory$ReaderIterator.<init>(ReaderIteratorFactory.java:161)\n",
            "\tat edu.stanford.nlp.objectbank.ResettableReaderIteratorFactory.iterator(ResettableReaderIteratorFactory.java:98)\n",
            "\tat edu.stanford.nlp.objectbank.ObjectBank$OBIterator.<init>(ObjectBank.java:411)\n",
            "\tat edu.stanford.nlp.objectbank.ObjectBank.iterator(ObjectBank.java:250)\n",
            "\tat edu.stanford.nlp.sequences.ObjectBankWrapper.iterator(ObjectBankWrapper.java:45)\n",
            "\tat edu.stanford.nlp.ie.crf.CRFClassifier.train(CRFClassifier.java:1542)\n",
            "\tat edu.stanford.nlp.ie.AbstractSequenceClassifier.train(AbstractSequenceClassifier.java:774)\n",
            "\tat edu.stanford.nlp.ie.AbstractSequenceClassifier.train(AbstractSequenceClassifier.java:762)\n",
            "\tat edu.stanford.nlp.ie.crf.CRFClassifier.main(CRFClassifier.java:2967)\n",
            "Caused by: java.io.FileNotFoundException: /Users/jacklinewambui/Desktop/finalProject/CS72 Project_Emails_training_dataset_StanfordNER.tsv (No such file or directory)\n",
            "\tat java.base/java.io.FileInputStream.open0(Native Method)\n",
            "\tat java.base/java.io.FileInputStream.open(FileInputStream.java:211)\n",
            "\tat java.base/java.io.FileInputStream.<init>(FileInputStream.java:153)\n",
            "\tat edu.stanford.nlp.io.IOUtils.inputStreamFromFile(IOUtils.java:535)\n",
            "\t... 11 more\n",
            "\n"
          ]
        }
      ],
      "source": [
        "jar_path = \"/Users/jacklinewambui/Desktop/finalProject/stanford-ner.jar\"\n",
        "prop_file = \"/Users/jacklinewambui/Desktop/finalProject/ner-training.prop\"\n",
        "\n",
        "command = f\"java -cp {jar_path} edu.stanford.nlp.ie.crf.CRFClassifier -prop {prop_file}\"\n",
        "\n",
        "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "\n",
        "print(\"Exit code:\", result.returncode)\n",
        "print(\"Error output:\", result.stderr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8HgGu0oHmPT"
      },
      "source": [
        "Tokenize the text and assign labels (i.e DATE, LOCATION, PERSON, etc) to formed tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "BXrSgHjEHbxx"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "def testStanfordNERTTagger(text):\n",
        "\tst = StanfordNERTagger('/Users/jacklinewambui/Desktop/finalProject/ner-model.ser.gz',\n",
        "\t\t\t\t\t\t\t'/Users/jacklinewambui/Desktop/finalProject/stanford-ner.jar',\n",
        "\t\t\t\t\t\t\tencoding='utf-8')\n",
        "\n",
        "\ttokenized_text = word_tokenize(text)\n",
        "\tclassified_text = st.tag(tokenized_text)\n",
        "\n",
        "\treturn classified_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "O2b_gb7EHgfH"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n\n===========================================================================\nNLTK was unable to find the /Users/jacklinewambui/Desktop/finalProject/ner-model.ser.gz file!\nUse software specific configuration parameters or set the STANFORD_MODELS environment variable.\n===========================================================================",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtestStanfordNERTTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthis is a test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[79], line 4\u001b[0m, in \u001b[0;36mtestStanfordNERTTagger\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtestStanfordNERTTagger\u001b[39m(text):\n\u001b[0;32m----> 4\u001b[0m \tst \u001b[38;5;241m=\u001b[39m \u001b[43mStanfordNERTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/jacklinewambui/Desktop/finalProject/ner-model.ser.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m\t\t\t\t\t\t\t\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/jacklinewambui/Desktop/finalProject/stanford-ner.jar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m\t\t\t\t\t\t\t\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \ttokenized_text \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[1;32m      9\u001b[0m \tclassified_text \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mtag(tokenized_text)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/tag/stanford.py:200\u001b[0m, in \u001b[0;36mStanfordNERTagger.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 200\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/tag/stanford.py:74\u001b[0m, in \u001b[0;36mStanfordTagger.__init__\u001b[0;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[1;32m     65\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     66\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe StanfordTagger class is not meant to be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minstantiated directly. Did you mean \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mStanfordPOSTagger or StanfordNERTagger?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n\u001b[1;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stanford_jar \u001b[39m=\u001b[39m find_jar(\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_JAR, path_to_jar, searchpath\u001b[39m=\u001b[39m(), url\u001b[39m=\u001b[39m_stanford_url, verbose\u001b[39m=\u001b[39mverbose\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stanford_model \u001b[39m=\u001b[39m find_file(\n\u001b[1;32m     75\u001b[0m     model_filename, env_vars\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mSTANFORD_MODELS\u001b[39;49m\u001b[39m\"\u001b[39;49m,), verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encoding \u001b[39m=\u001b[39m encoding\n\u001b[1;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_options \u001b[39m=\u001b[39m java_options\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/internals.py:626\u001b[0m, in \u001b[0;36mfind_file\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_file\u001b[39m(\n\u001b[1;32m    624\u001b[0m     filename, env_vars\u001b[39m=\u001b[39m(), searchpath\u001b[39m=\u001b[39m(), file_names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    625\u001b[0m ):\n\u001b[0;32m--> 626\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m    627\u001b[0m         find_file_iter(filename, env_vars, searchpath, file_names, url, verbose)\n\u001b[1;32m    628\u001b[0m     )\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/internals.py:620\u001b[0m, in \u001b[0;36mfind_file_iter\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[1;32m    618\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  For more information on \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m, see:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    <\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    619\u001b[0m div \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m75\u001b[39m\n\u001b[0;32m--> 620\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiv\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiv\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the /Users/jacklinewambui/Desktop/finalProject/ner-model.ser.gz file!\nUse software specific configuration parameters or set the STANFORD_MODELS environment variable.\n==========================================================================="
          ]
        }
      ],
      "source": [
        "testStanfordNERTTagger(\"this is a test\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
